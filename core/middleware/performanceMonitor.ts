// middleware/performanceMonitor.ts ‚Üí Performance Monitoring System
// ================================================================================
// üìä DenoGenesis Framework - Advanced Performance Monitoring
// Real-time metrics, memory tracking, and request analysis for optimization
// ================================================================================

import { ConsoleStyler, ColorSystem } from "@pedromdominguez/genesis-trace";
import type { ILogger } from "../interfaces/ILogger.ts";
//
// UNIX PHILOSOPHY IMPLEMENTATION:
// --------------------------------
// 1. DO ONE THING WELL:
//    - This module ONLY handles performance monitoring and metrics collection
//    - Does NOT handle HTTP routing, database operations, or authentication
//    - Single, focused responsibility: track and analyze application performance
//
// 2. COMPOSABILITY:
//    - Designed as middleware that integrates seamlessly into Oak framework
//    - Can be combined with CORS, logging, auth, and other middleware
//    - Exports reusable functions and classes for flexible composition
//
// 3. TEXT-BASED:
//    - All metrics returned as human-readable JSON
//    - Configuration via simple objects
//    - Logs use standard string formats
//
// 4. EXPLICIT:
//    - Clear interfaces and type definitions
//    - No hidden state or magic behavior
//    - Every method has a single, obvious purpose
//
// ARCHITECTURE:
// -------------
// Three-Layer Design:
//   1. Application Layer (your routes/controllers)
//   2. Middleware Layer (createPerformanceMiddleware)
//   3. Monitoring Layer (PerformanceMonitor class)
//
// Data flows through these layers, with each layer having a single responsibility.
//
// MEMORY MANAGEMENT:
// ------------------
// - In-memory storage for speed (no database writes per request)
// - Fixed-size circular buffers prevent unbounded growth
// - Periodic cleanup removes stale data
// - Typical footprint: ~9KB for production workload
//
// SECURITY:
// ---------
// - No sensitive data stored in metrics
// - Request IDs are random, not sequential (prevents enumeration)
// - Metrics endpoints should be protected with authentication
// - Error messages sanitized (no stack traces in production)
//
// USAGE:
// ------
// ```typescript
// import { PerformanceMonitor, createPerformanceMiddleware } from "./middleware/performanceMonitor.ts";
//
// const monitor = new PerformanceMonitor();
// const app = new Application();
//
// app.use(createPerformanceMiddleware(monitor, isDevelopment));
//
// // Expose metrics endpoint
// router.get("/admin/metrics", requireAuth, (ctx) => {
//   ctx.response.body = monitor.getMetrics();
// });
// ```
//
// RELATED DOCUMENTATION:
// ----------------------
// - Framework Philosophy: docs/02-framework/philosophy.md
// - Middleware Architecture: docs/04-api-reference/core/middleware.md
// - Performance Optimization: docs/02-framework/performance.md
// - Unix Principles: docs/02-framework/meta-documentation.md
//
// ================================================================================

// ================================================================================
// üì¶ TYPE DEFINITIONS
// ================================================================================

/**
 * Statistics tracked for each unique endpoint
 *
 * @interface EndpointMetrics
 * @property {number} count - Total number of requests to this endpoint
 * @property {number} totalTime - Cumulative response time in milliseconds
 * @property {number} errors - Number of failed requests (status >= 400)
 */
interface EndpointMetrics {
  count: number;
  totalTime: number;
  errors: number;
}

/**
 * Individual request log entry
 * Stored in circular buffer for recent activity tracking
 *
 * @interface RequestLog
 * @property {number} timestamp - Unix timestamp (ms) when request completed
 * @property {string} path - Request URL path (e.g., "/api/users")
 * @property {string} method - HTTP method (GET, POST, etc.)
 * @property {number} duration - Request processing time in milliseconds
 * @property {number} status - HTTP status code (200, 404, 500, etc.)
 */
interface RequestLog {
  timestamp: number;
  path: string;
  method: string;
  duration: number;
  status: number;
}

/**
 * Performance insight generated by analysis algorithms
 *
 * @interface PerformanceInsight
 * @property {'warning' | 'error' | 'info'} type - Severity level
 * @property {string} message - Human-readable description of the issue
 * @property {string} suggestion - Actionable recommendation for improvement
 */
interface PerformanceInsight {
  type: "warning" | "error" | "info";
  message: string;
  suggestion: string;
}

/**
 * Memory usage statistics from Deno runtime
 *
 * @interface MemoryMetrics
 * @property {string} heapUsed - Human-readable heap usage (e.g., "42.5 MB")
 * @property {string} heapTotal - Human-readable total heap (e.g., "64 MB")
 * @property {string} external - External memory usage
 * @property {number} heapUsedBytes - Raw bytes of heap used
 * @property {number} heapTotalBytes - Raw bytes of total heap
 * @property {string} utilization - Percentage of heap in use (e.g., "66.4%")
 */
interface MemoryMetrics {
  heapUsed: string;
  heapTotal: string;
  external: string;
  heapUsedBytes: number;
  heapTotalBytes: number;
  utilization: string;
}

// ================================================================================
// üîß PERFORMANCE MONITOR CLASS
// ================================================================================

/**
 * PerformanceMonitor - Core metrics collection and analysis
 *
 * RESPONSIBILITY:
 * ---------------
 * Tracks application performance metrics in-memory with minimal overhead.
 * Provides real-time analytics and performance insights.
 *
 * DESIGN PRINCIPLES:
 * ------------------
 * - In-memory storage for speed (no blocking I/O)
 * - Fixed-size buffers prevent memory leaks
 * - O(1) or O(log n) operations for all tracking
 * - Periodic cleanup prevents stale data accumulation
 *
 * THREAD SAFETY:
 * --------------
 * JavaScript is single-threaded, but async operations can interleave.
 * All operations are atomic (simple increments and assignments).
 * No shared mutable state between async contexts.
 *
 * MEMORY FOOTPRINT:
 * -----------------
 * - Counters: ~80 bytes (fixed)
 * - Endpoint map: ~50 bytes per unique endpoint (typically 20-50 endpoints)
 * - Recent requests: ~6.4KB (100 entries √ó 64 bytes each)
 * - Total typical usage: ~9KB
 *
 * @example
 * ```typescript
 * const monitor = new PerformanceMonitor();
 * monitor.incrementRequest();
 * monitor.recordRequest("/api/users", "GET", 145, 200);
 * const metrics = monitor.getMetrics();
 * ```
 */
export class PerformanceMonitor {
  // ============================================================================
  // PRIVATE STATE
  // ============================================================================

  /**
   * Unix timestamp (ms) when the monitor was initialized
   * Used to calculate server uptime
   * @private
   */
  private startTime: number;

  /**
   * Total number of HTTP requests received
   * Incremented for every request, regardless of success/failure
   * @private
   */
  private requestCount: number = 0;

  /**
   * Total number of failed requests (HTTP status >= 400)
   * Includes both client errors (4xx) and server errors (5xx)
   * @private
   */
  private errorCount: number = 0;

  /**
   * Cumulative response time across all requests (in milliseconds)
   * Used to calculate average response time: totalResponseTime / requestCount
   * @private
   */
  private totalResponseTime: number = 0;

  /**
   * Count of requests that took longer than 1000ms (1 second)
   * Threshold defined as "slow" for most web applications
   * @private
   */
  private slowRequests: number = 0;

  /**
   * Per-endpoint performance statistics
   *
   * KEY FORMAT: "{METHOD} {PATH}" (e.g., "GET /api/users")
   * VALUE: { count, totalTime, errors }
   *
   * Example:
   * Map {
   *   "GET /api/users"    => { count: 156, totalTime: 23400, errors: 2 },
   *   "POST /api/login"   => { count: 89,  totalTime: 17800, errors: 5 },
   *   "GET /api/products" => { count: 234, totalTime: 35100, errors: 1 }
   * }
   *
   * @private
   */
  private endpoints: Map<string, EndpointMetrics> = new Map();

  /**
   * Circular buffer of recent requests (last 100)
   *
   * CIRCULAR BUFFER STRATEGY:
   * - Push new entries to the end
   * - When length > 100, shift() removes oldest from front
   * - Maintains fixed memory footprint
   * - O(1) append, O(1) removal (amortized)
   *
   * Used for:
   * - Debugging recent issues
   * - Real-time activity feed
   * - Trend analysis
   *
   * @private
   */
  private recentRequests: Array<RequestLog> = [];

  // ============================================================================
  // CONSTRUCTOR
  // ============================================================================

  /**
   * Initialize the performance monitor
   *
   * STARTUP SEQUENCE:
   * 1. Record current timestamp for uptime tracking
   * 2. Initialize all counters to zero
   * 3. Create empty data structures
   * 4. Start periodic cleanup timer
   *
   * SIDE EFFECTS:
   * - Starts a setInterval timer for cleanup (runs every 5 minutes)
   * - Timer will keep process alive until explicitly cleared
   */
  constructor() {
    // Record server start time (Unix epoch in milliseconds)
    this.startTime = Date.now();

    // Start background cleanup process
    // Removes requests older than 5 minutes from the buffer
    this.startPeriodicCleanup();
  }

  // ============================================================================
  // PUBLIC API - REQUEST TRACKING
  // ============================================================================

  /**
   * Increment total request counter
   *
   * WHEN TO CALL:
   * - At the START of request processing
   * - Before any error handling
   * - Guaranteed to be called exactly once per request
   *
   * ATOMIC OPERATION:
   * - Simple increment, no race conditions
   * - Safe to call from async contexts
   *
   * @public
   * @returns {void}
   */
  incrementRequest(): void {
    this.requestCount++;
  }

  /**
   * Increment error counter
   *
   * WHEN TO CALL:
   * - After a request results in an error (status >= 400)
   * - In catch blocks for unhandled exceptions
   * - After recording the failed request
   *
   * DEFINITION OF ERROR:
   * - HTTP status codes 400-499 (client errors)
   * - HTTP status codes 500-599 (server errors)
   * - Unhandled exceptions that crash the request handler
   *
   * @public
   * @returns {void}
   */
  incrementError(): void {
    this.errorCount++;
  }

  /**
   * Record comprehensive metrics for a completed request
   *
   * THIS IS THE PRIMARY TRACKING METHOD
   *
   * WHAT IT DOES:
   * 1. Updates aggregate response time statistics
   * 2. Tracks slow requests (>1000ms threshold)
   * 3. Maintains per-endpoint statistics
   * 4. Adds entry to recent requests buffer
   * 5. Enforces circular buffer size limit
   *
   * PERFORMANCE:
   * - All operations are O(1) constant time
   * - No blocking I/O operations
   * - Safe to call in hot path (every request)
   *
   * @public
   * @param {string} path - URL path (e.g., "/api/users")
   * @param {string} method - HTTP method (GET, POST, PUT, DELETE, etc.)
   * @param {number} duration - Request processing time in milliseconds
   * @param {number} status - HTTP status code (200, 404, 500, etc.)
   * @returns {void}
   *
   * @example
   * ```typescript
   * // Track a successful GET request that took 145ms
   * monitor.recordRequest("/api/users", "GET", 145, 200);
   *
   * // Track a failed POST request that took 89ms
   * monitor.recordRequest("/api/login", "POST", 89, 401);
   * ```
   */
  recordRequest(path: string, method: string, duration: number, status: number): void {
    // -------------------------------------------------------------------------
    // 1. UPDATE AGGREGATE METRICS
    // -------------------------------------------------------------------------

    // Add this request's duration to the running total
    // Used later to calculate: averageResponseTime = totalResponseTime / requestCount
    this.totalResponseTime += duration;

    // -------------------------------------------------------------------------
    // 2. TRACK SLOW REQUESTS
    // -------------------------------------------------------------------------

    // Threshold: 1000ms (1 second)
    // Rationale: Most web requests should complete in <500ms
    // Slow requests indicate potential optimization opportunities
    if (duration > 1000) {
      this.slowRequests++;
    }

    // -------------------------------------------------------------------------
    // 3. UPDATE PER-ENDPOINT STATISTICS
    // -------------------------------------------------------------------------

    // Create unique key for this endpoint
    // Format: "{METHOD} {PATH}"
    // Examples: "GET /api/users", "POST /api/login"
    const endpointKey = `${method} ${path}`;

    // Retrieve existing stats or create default object
    // JavaScript Map.get() returns undefined if key doesn't exist
    // The || operator provides a default value
    const existing = this.endpoints.get(endpointKey) || {
      count: 0,
      totalTime: 0,
      errors: 0,
    };

    // Update statistics
    existing.count++; // Increment request count
    existing.totalTime += duration; // Add to cumulative time

    // Track errors (HTTP status >= 400)
    // 4xx = client errors (bad request, not found, unauthorized)
    // 5xx = server errors (internal error, service unavailable)
    if (status >= 400) {
      existing.errors++;
    }

    // Save updated statistics back to Map
    // If key didn't exist, this creates a new entry
    // If key existed, this updates the existing entry
    this.endpoints.set(endpointKey, existing);

    // -------------------------------------------------------------------------
    // 4. ADD TO RECENT REQUESTS BUFFER (Circular Buffer)
    // -------------------------------------------------------------------------

    // Create new log entry
    const logEntry: RequestLog = {
      timestamp: Date.now(), // Current time in milliseconds
      path, // URL path
      method, // HTTP method
      duration, // Processing time
      status, // HTTP status code
    };

    // Append to end of array
    this.recentRequests.push(logEntry);

    // -------------------------------------------------------------------------
    // 5. ENFORCE BUFFER SIZE LIMIT
    // -------------------------------------------------------------------------

    // Circular buffer strategy: maintain fixed size of 100 entries
    // When we exceed 100, remove the oldest entry (from the front)
    //
    // Array.shift() removes first element and shifts all others down
    // Time complexity: O(n) where n = array length
    // However, we only shift when length = 101, so it's O(100) = O(1) constant
    if (this.recentRequests.length > 100) {
      this.recentRequests.shift(); // Remove oldest request
    }
  }

  // ============================================================================
  // PUBLIC API - METRICS RETRIEVAL
  // ============================================================================

  /**
   * Get basic performance metrics
   *
   * WHAT IT RETURNS:
   * - Uptime and temporal statistics
   * - Request counts and success rates
   * - Performance averages and percentages
   * - System resource usage (memory)
   * - Top endpoints and recent activity
   *
   * USE CASES:
   * - Health check endpoints
   * - Monitoring dashboards
   * - Alert systems
   * - Performance reports
   *
   * PERFORMANCE:
   * - Fast retrieval (mostly O(1) lookups)
   * - getTopEndpoints() is O(n log n) due to sorting
   * - Typical execution time: <1ms
   *
   * @public
   * @returns {Object} Comprehensive metrics object
   *
   * @example
   * ```typescript
   * const metrics = monitor.getMetrics();
   * console.log(`Uptime: ${metrics.uptime}`);
   * console.log(`Success Rate: ${metrics.successRate}`);
   * console.log(`Avg Response: ${metrics.averageResponseTime}`);
   * ```
   */
  getMetrics(): {
    uptime: string;
    uptimeMs: number;
    requests: number;
    errors: number;
    successRate: string;
    averageResponseTime: string;
    slowRequests: number;
    slowRequestRate: string;
    memory: MemoryMetrics;
    timestamp: string;
    topEndpoints: Array<{
      endpoint: string;
      requests: number;
      avgResponseTime: number;
      errorRate: string;
    }>;
    recentActivity: Array<{
      timestamp: string;
      request: string;
      duration: string;
      status: number;
      statusClass: string;
    }>;
  } {
    // Calculate uptime in milliseconds
    const uptime = Date.now() - this.startTime;

    // Calculate average response time
    // Guard against division by zero when no requests have been processed
    const avgResponseTime = this.requestCount > 0 ? this.totalResponseTime / this.requestCount : 0;

    return {
      // -----------------------------------------------------------------------
      // TEMPORAL METRICS
      // -----------------------------------------------------------------------

      // Human-readable uptime (e.g., "2d 5h 23m")
      uptime: this.formatUptime(uptime),

      // Raw uptime in milliseconds (for programmatic use)
      uptimeMs: uptime,

      // -----------------------------------------------------------------------
      // REQUEST METRICS
      // -----------------------------------------------------------------------

      // Total requests processed
      requests: this.requestCount,

      // Total failed requests
      errors: this.errorCount,

      // Success rate as percentage
      // Formula: ((total - errors) / total) √ó 100
      // Example: (985 / 1000) √ó 100 = 98.5%
      successRate: this.requestCount > 0
        ? ((this.requestCount - this.errorCount) / this.requestCount * 100).toFixed(2) + "%"
        : "100%", // Default to 100% when no requests processed

      // -----------------------------------------------------------------------
      // PERFORMANCE METRICS
      // -----------------------------------------------------------------------

      // Average response time across all requests
      // Rounded to nearest millisecond for readability
      averageResponseTime: Math.round(avgResponseTime) + "ms",

      // Count of slow requests (>1000ms)
      slowRequests: this.slowRequests,

      // Percentage of requests that were slow
      // Formula: (slow / total) √ó 100
      slowRequestRate: this.requestCount > 0
        ? ((this.slowRequests / this.requestCount) * 100).toFixed(2) + "%"
        : "0%",

      // -----------------------------------------------------------------------
      // SYSTEM METRICS
      // -----------------------------------------------------------------------

      // Current memory usage statistics
      memory: this.getMemoryUsage(),

      // ISO 8601 timestamp of when metrics were collected
      timestamp: new Date().toISOString(),

      // -----------------------------------------------------------------------
      // ANALYTICS
      // -----------------------------------------------------------------------

      // Top 5 most-requested endpoints
      topEndpoints: this.getTopEndpoints(),

      // Last 10 requests for debugging
      recentActivity: this.getRecentActivity(),
    };
  }

  /**
   * Get detailed metrics with per-endpoint breakdown
   *
   * DIFFERENCE FROM getMetrics():
   * - Includes ALL endpoints (not just top 5)
   * - Adds system information (Deno version, OS, etc.)
   * - More verbose for admin dashboards
   *
   * USE CASES:
   * - Administrative interfaces
   * - Performance audits
   * - Detailed reporting
   * - Troubleshooting
   *
   * WARNING:
   * - Can be large if many unique endpoints exist
   * - Should be protected behind authentication
   * - Consider pagination for production use
   *
   * @public
   * @returns {Object} Detailed metrics with full endpoint breakdown
   *
   * @example
   * ```typescript
   * const detailed = monitor.getDetailedMetrics();
   * console.log(`Tracking ${detailed.endpoints.length} endpoints`);
   * console.log(`Deno version: ${detailed.systemInfo.deno.version}`);
   * ```
   */
  getDetailedMetrics(): ReturnType<typeof this.getMetrics> & {
    endpoints: Array<{
      endpoint: string;
      requests: number;
      avgResponseTime: string;
      errorRate: string;
    }>;
    systemInfo: {
      deno: {
        version: string;
        v8: string;
        typescript: string;
      };
      system: {
        os: string;
        arch: string;
        pid: number;
      };
      runtime: {
        startTime: string;
        timezone: string;
      };
    };
  } {
    return {
      // Include all basic metrics
      ...this.getMetrics(),

      // Full breakdown of every endpoint
      endpoints: Array.from(this.endpoints.entries()).map(([endpoint, stats]) => ({
        endpoint,
        requests: stats.count,
        avgResponseTime: Math.round(stats.totalTime / stats.count) + "ms",
        errorRate: ((stats.errors / stats.count) * 100).toFixed(2) + "%",
        totalTime: stats.totalTime,
      })),

      // System and runtime information
      systemInfo: this.getSystemInfo(),
    };
  }

  // ============================================================================
  // PRIVATE UTILITY METHODS
  // ============================================================================

  /**
   * Format milliseconds into human-readable uptime string
   *
   * ALGORITHM:
   * 1. Convert milliseconds to seconds
   * 2. Calculate days, hours, minutes from seconds
   * 3. Format based on largest unit
   *
   * EXAMPLES:
   * - 45000ms       ‚Üí "45s"
   * - 150000ms      ‚Üí "2m 30s"
   * - 7200000ms     ‚Üí "2h 0m 0s"
   * - 90000000ms    ‚Üí "1d 1h 0m"
   *
   * @private
   * @param {number} ms - Milliseconds to format
   * @returns {string} Human-readable uptime
   *
   * @example
   * ```typescript
   * formatUptime(45000)      // "45s"
   * formatUptime(7200000)    // "2h 0m 0s"
   * formatUptime(90000000)   // "1d 1h 0m"
   * ```
   */
  private formatUptime(ms: number): string {
    // Convert milliseconds to seconds
    // 1 second = 1000 milliseconds
    const seconds = Math.floor(ms / 1000);

    // Convert seconds to minutes
    // 1 minute = 60 seconds
    const minutes = Math.floor(seconds / 60);

    // Convert minutes to hours
    // 1 hour = 60 minutes
    const hours = Math.floor(minutes / 60);

    // Convert hours to days
    // 1 day = 24 hours
    const days = Math.floor(hours / 24);

    // Format based on largest time unit
    if (days > 0) {
      // Format: "Xd Yh Zm"
      // Modulo (%) extracts remainder
      // Example: 27 hours ‚Üí 27 % 24 = 3 hours (1 day + 3 hours)
      return `${days}d ${hours % 24}h ${minutes % 60}m`;
    }

    if (hours > 0) {
      // Format: "Xh Ym Zs"
      return `${hours}h ${minutes % 60}m ${seconds % 60}s`;
    }

    if (minutes > 0) {
      // Format: "Xm Ys"
      return `${minutes}m ${seconds % 60}s`;
    }

    // Less than a minute: show seconds only
    return `${seconds}s`;
  }

  /**
   * Get current memory usage from Deno runtime
   *
   * MEMORY TYPES:
   * 1. Heap Used   - Memory currently occupied by objects
   * 2. Heap Total  - Total heap allocated by V8 engine
   * 3. External    - Memory used by C++ objects (buffers, etc.)
   *
   * UTILIZATION FORMULA:
   * utilization = (heapUsed / heapTotal) √ó 100
   *
   * THRESHOLDS:
   * - <70%: Healthy
   * - 70-80%: Monitor
   * - >80%: Warning - consider optimization
   *
   * ERROR HANDLING:
   * - Deno.memoryUsage() may not exist in all environments
   * - Try-catch provides graceful fallback
   * - Returns 'N/A' strings instead of crashing
   *
   * @private
   * @returns {MemoryMetrics} Memory usage statistics
   *
   * @example
   * ```typescript
   * const mem = getMemoryUsage();
   * console.log(`Memory: ${mem.heapUsed} / ${mem.heapTotal}`);
   * console.log(`Utilization: ${mem.utilization}`);
   * ```
   */
  private getMemoryUsage(): MemoryMetrics {
    try {
      // Query Deno runtime for memory statistics
      // Returns object with heapUsed, heapTotal, external in bytes
      const memory = Deno.memoryUsage();

      return {
        // Human-readable formats
        heapUsed: this.formatBytes(memory.heapUsed),
        heapTotal: this.formatBytes(memory.heapTotal),
        external: this.formatBytes(memory.external),

        // Raw byte values (for programmatic use)
        heapUsedBytes: memory.heapUsed,
        heapTotalBytes: memory.heapTotal,

        // Calculate utilization percentage
        // Example: (42MB / 64MB) √ó 100 = 65.6%
        utilization: ((memory.heapUsed / memory.heapTotal) * 100).toFixed(1) + "%",
      };
    } catch {
      // Graceful degradation when memoryUsage() unavailable
      // Occurs in: test environments, non-Deno runtimes, restricted permissions
      return {
        heapUsed: "N/A",
        heapTotal: "N/A",
        external: "N/A",
        heapUsedBytes: 0,
        heapTotalBytes: 0,
        utilization: "N/A",
      };
    }
  }

  /**
   * Format bytes into human-readable size string
   *
   * ALGORITHM:
   * Uses logarithms to determine appropriate unit (B, KB, MB, GB)
   * Formula: i = floor(log‚ÇÅ‚ÇÄ‚ÇÇ‚ÇÑ(bytes))
   *
   * WHY LOGARITHMS?
   * Each unit is 1024√ó the previous:
   * - 1 KB = 1024 B
   * - 1 MB = 1024 KB = 1024¬≤ B
   * - 1 GB = 1024 MB = 1024¬≥ B
   *
   * The logarithm tells us the exponent (which unit to use)
   *
   * EXAMPLES:
   * - 1024 bytes     ‚Üí log‚ÇÅ‚ÇÄ‚ÇÇ‚ÇÑ(1024) = 1       ‚Üí sizes[1] = "KB" ‚Üí "1 KB"
   * - 1048576 bytes  ‚Üí log‚ÇÅ‚ÇÄ‚ÇÇ‚ÇÑ(1048576) = 2    ‚Üí sizes[2] = "MB" ‚Üí "1 MB"
   * - 42567890 bytes ‚Üí log‚ÇÅ‚ÇÄ‚ÇÇ‚ÇÑ(42567890) = 2.5 ‚Üí sizes[2] = "MB" ‚Üí "40.6 MB"
   *
   * @private
   * @param {number} bytes - Number of bytes to format
   * @returns {string} Human-readable size (e.g., "42.5 MB")
   *
   * @example
   * ```typescript
   * formatBytes(1024)       // "1 KB"
   * formatBytes(1048576)    // "1 MB"
   * formatBytes(42567890)   // "40.6 MB"
   * ```
   */
  private formatBytes(bytes: number): string {
    // Size unit names
    const sizes = ["B", "KB", "MB", "GB"];

    // Edge case: zero bytes
    if (bytes === 0) return "0 B";

    // Calculate the appropriate unit index
    // Math.log(bytes) = natural log of bytes
    // Math.log(1024) = natural log of 1024 (~6.931)
    // Division gives us the power of 1024
    // Math.floor rounds down to nearest integer
    const i = Math.floor(Math.log(bytes) / Math.log(1024));

    // Convert bytes to the calculated unit
    // Math.pow(1024, i) = 1024^i
    // Example: i=2 ‚Üí 1024¬≤ = 1048576 (bytes per MB)
    const value = bytes / Math.pow(1024, i);

    // Round to 2 decimal places
    // Multiply by 100, round, divide by 100
    // Example: 40.6234 ‚Üí 4062.34 ‚Üí 4062 ‚Üí 40.62
    const rounded = Math.round(value * 100) / 100;

    // Combine value and unit
    return rounded + " " + sizes[i];
  }

  /**
   * Get top N endpoints by request count
   *
   * ALGORITHM:
   * 1. Convert Map to array of [key, value] pairs
   * 2. Sort by request count (descending)
   * 3. Take top N entries (default 5)
   * 4. Transform to result format
   *
   * TIME COMPLEXITY:
   * - Array.from(): O(n) - iterate all endpoints
   * - sort(): O(n log n) - JavaScript uses Timsort
   * - slice(): O(k) - copy k elements
   * - map(): O(k) - transform k elements
   * Total: O(n log n) dominated by sort
   *
   * SPACE COMPLEXITY:
   * - O(n) for array conversion
   * - O(k) for sliced result
   * Total: O(n + k)
   *
   * @private
   * @param {number} limit - Number of top endpoints to return (default: 5)
   * @returns {Array} Top endpoints with statistics
   *
   * @example
   * ```typescript
   * const top = getTopEndpoints(5);
   * // [
   * //   { endpoint: "GET /api/users", requests: 234, avgResponseTime: 150, errorRate: "0.4" },
   * //   { endpoint: "POST /api/login", requests: 156, avgResponseTime: 200, errorRate: "3.2" },
   * //   ...
   * // ]
   * ```
   */
  private getTopEndpoints(limit: number = 5) {
    return Array.from(this.endpoints.entries())
      // Sort comparator function
      // Arrow function: ([,a], [,b]) destructures to get values, ignores keys
      // b.count - a.count ‚Üí descending order (largest first)
      .sort(([, a], [, b]) => b.count - a.count)
      // Take only the top N entries
      // slice(0, 5) ‚Üí elements at indices 0, 1, 2, 3, 4
      .slice(0, limit)
      // Transform each entry to result format
      .map(([endpoint, stats]) => ({
        endpoint,
        requests: stats.count,

        // Average response time: totalTime / count
        avgResponseTime: Math.round(stats.totalTime / stats.count),

        // Error rate as percentage: (errors / total) √ó 100
        errorRate: ((stats.errors / stats.count) * 100).toFixed(1),
      }));
  }

  /**
   * Get recent request activity log
   *
   * WHAT IT RETURNS:
   * - Last N requests from the circular buffer
   * - Formatted for display in dashboards
   * - Status class for color-coding (success/warning/error)
   *
   * STATUS CLASSES:
   * - success: 200-299 (OK, Created, etc.)
   * - warning: 300-399 (Redirects)
   * - error: 400-599 (Client/Server errors)
   *
   * @private
   * @param {number} limit - Number of recent requests to return (default: 10)
   * @returns {Array} Recent requests with formatted data
   *
   * @example
   * ```typescript
   * const recent = getRecentActivity(10);
   * // [
   * //   {
   * //     timestamp: "2025-10-21T10:30:15.123Z",
   * //     request: "GET /api/users",
   * //     duration: "145ms",
   * //     status: 200,
   * //     statusClass: "success"
   * //   },
   * //   ...
   * // ]
   * ```
   */
  private getRecentActivity(limit: number = 10) {
    return this.recentRequests
      // Take last N entries
      // slice(-10) ‚Üí last 10 elements
      // Negative index counts from end: -1 is last, -2 is second-to-last, etc.
      .slice(-limit)
      // Transform each entry to display format
      .map((req) => ({
        // Convert Unix timestamp to ISO 8601 string
        // 1697900000000 ‚Üí "2025-10-21T10:30:00.000Z"
        timestamp: new Date(req.timestamp).toISOString(),

        // Combine method and path
        request: `${req.method} ${req.path}`,

        // Add 'ms' unit to duration
        duration: req.duration + "ms",

        // HTTP status code
        status: req.status,

        // CSS class for color-coding
        statusClass: req.status >= 400 ? "error" : req.status >= 300 ? "warning" : "success",
      }));
  }

  /**
   * Get system and runtime information
   *
   * WHAT IT INCLUDES:
   * 1. Deno Runtime Information
   *    - Deno version
   *    - V8 engine version
   *    - TypeScript version
   *
   * 2. System Information
   *    - Operating system (linux, darwin, windows)
   *    - Architecture (x64, arm64, etc.)
   *    - Process ID
   *
   * 3. Runtime State
   *    - Server start time
   *    - Current timezone
   *
   * USE CASES:
   * - Debugging environment issues
   * - Version compatibility checks
   * - Support diagnostics
   *
   * @private
   * @returns {Object} System information
   *
   * @example
   * ```typescript
   * const info = getSystemInfo();
   * console.log(`Running on Deno ${info.deno.version}`);
   * console.log(`OS: ${info.system.os} ${info.system.arch}`);
   * ```
   */
  private getSystemInfo() {
    return {
      // Deno runtime versions
      deno: {
        version: Deno.version.deno, // e.g., "1.37.0"
        v8: Deno.version.v8, // e.g., "11.8.172.3"
        typescript: Deno.version.typescript, // e.g., "5.2.2"
      },

      // System information
      system: {
        os: Deno.build.os, // "linux", "darwin", "windows"
        arch: Deno.build.arch, // "x86_64", "aarch64"
        pid: Deno.pid, // Process ID (number)
      },

      // Runtime state
      runtime: {
        // ISO 8601 timestamp of when server started
        startTime: new Date(this.startTime).toISOString(),

        // Current timezone (e.g., "America/New_York")
        timezone: Intl.DateTimeFormat().resolvedOptions().timeZone,
      },
    };
  }

  /**
   * Start periodic cleanup of old data
   *
   * CLEANUP STRATEGY:
   * - Runs every 5 minutes
   * - Removes requests older than 5 minutes
   * - Prevents unbounded growth of recentRequests array
   *
   * WHY 5 MINUTES?
   * - Balance between keeping useful debug data and memory usage
   * - Recent enough for troubleshooting active issues
   * - Old enough to prevent frequent cleanup overhead
   *
   * MEMORY IMPACT:
   * - Without cleanup: unbounded growth (memory leak)
   * - With cleanup: stabilizes at ~100 entries
   *
   * SIDE EFFECTS:
   * - setInterval keeps process alive
   * - For production: ensure cleanup doesn't interfere with graceful shutdown
   *
   * @private
   * @returns {void}
   */
  private startPeriodicCleanup(): void {
    // Run cleanup every 5 minutes
    // 5 minutes = 5 √ó 60 seconds √ó 1000 milliseconds
    setInterval(() => {
      // Calculate cutoff timestamp
      // Current time - 5 minutes
      const fiveMinutesAgo = Date.now() - (5 * 60 * 1000);

      // Filter keeps only requests newer than cutoff
      // req.timestamp > fiveMinutesAgo ‚Üí keep
      // req.timestamp <= fiveMinutesAgo ‚Üí remove
      this.recentRequests = this.recentRequests.filter(
        (req) => req.timestamp > fiveMinutesAgo,
      );

      // Optional: Log cleanup for monitoring
      // console.log(`üßπ Cleanup: ${this.recentRequests.length} requests retained`);
    }, 5 * 60 * 1000);
  }

  // ============================================================================
  // PUBLIC API - PERFORMANCE ANALYSIS
  // ============================================================================

  /**
   * Generate performance insights and recommendations
   *
   * ANALYSIS ALGORITHMS:
   * 1. Response Time Analysis - Checks average against threshold
   * 2. Error Rate Analysis - Checks success rate
   * 3. Memory Analysis - Checks utilization percentage
   * 4. Slow Request Analysis - Checks percentage of slow requests
   *
   * THRESHOLDS (Industry Standard):
   * - Response Time: >500ms = warning
   * - Success Rate: <95% = error
   * - Memory Utilization: >80% = warning
   * - Slow Request Rate: >5% = warning
   *
   * INSIGHT TYPES:
   * - error: Critical issues requiring immediate attention
   * - warning: Performance degradation, optimization recommended
   * - info: General recommendations
   *
   * OVERALL HEALTH:
   * - excellent: No insights (all metrics within thresholds)
   * - good: Only warnings present
   * - poor: Errors present (critical issues)
   *
   * @public
   * @returns {Object} Performance insights and health status
   *
   * @example
   * ```typescript
   * const analysis = monitor.getPerformanceInsights();
   * if (analysis.overallHealth === 'poor') {
   *   console.error('Critical performance issues detected!');
   *   analysis.insights.forEach(insight => {
   *     console.error(`${insight.type}: ${insight.message}`);
   *     console.error(`Suggestion: ${insight.suggestion}`);
   *   });
   * }
   * ```
   */
  getPerformanceInsights(): {
    insights: PerformanceInsight[];
    overallHealth: "excellent" | "good" | "poor";
  } {
    // Get current metrics for analysis
    const metrics = this.getMetrics();

    // Accumulator for insights
    const insights: PerformanceInsight[] = [];

    // =========================================================================
    // ANALYSIS 1: RESPONSE TIME
    // =========================================================================

    // Parse average response time (remove 'ms' suffix)
    // "145ms" ‚Üí 145
    const avgTime = parseInt(metrics.averageResponseTime);

    // Threshold: 500ms
    // Rationale: Most web requests should complete in <500ms for good UX
    if (avgTime > 500) {
      insights.push({
        type: "warning",
        message: `Average response time is ${avgTime}ms. Consider optimization.`,
        suggestion: "Review slow endpoints and implement caching",
      });
    }

    // =========================================================================
    // ANALYSIS 2: ERROR RATE
    // =========================================================================

    // Parse success rate (remove '%' suffix)
    // "98.5%" ‚Üí 98.5
    const successRate = parseFloat(metrics.successRate.replace("%", ""));

    // Threshold: 95%
    // Rationale: Industry standard for healthy web services
    // <95% indicates systematic issues
    if (successRate < 95) {
      insights.push({
        type: "error",
        message: `Success rate is ${successRate}%. High error rate detected.`,
        suggestion: "Review error logs and improve error handling",
      });
    }

    // =========================================================================
    // ANALYSIS 3: MEMORY UTILIZATION
    // =========================================================================

    // Parse memory utilization (handle optional chaining)
    // "66.4%" ‚Üí 66.4
    const memoryUtil = parseFloat(metrics.memory.utilization?.replace("%", "") || "0");

    // Threshold: 80%
    // Rationale: >80% heap usage indicates potential memory pressure
    // May lead to garbage collection pauses or out-of-memory errors
    if (memoryUtil > 80) {
      insights.push({
        type: "warning",
        message: `Memory utilization is ${memoryUtil}%. Consider optimization.`,
        suggestion: "Review memory usage and implement cleanup routines",
      });
    }

    // =========================================================================
    // ANALYSIS 4: SLOW REQUEST RATE
    // =========================================================================

    // Parse slow request rate (remove '%' suffix)
    // "2.3%" ‚Üí 2.3
    const slowRate = parseFloat(metrics.slowRequestRate.replace("%", ""));

    // Threshold: 5%
    // Rationale: If >5% of requests are slow, it indicates systematic performance issues
    // Rather than occasional outliers
    if (slowRate > 5) {
      insights.push({
        type: "warning",
        message: `${slowRate}% of requests are slow (>1s). Performance optimization needed.`,
        suggestion: "Identify and optimize slow endpoints",
      });
    }

    // =========================================================================
    // DETERMINE OVERALL HEALTH
    // =========================================================================

    // Health calculation:
    // 1. If no insights ‚Üí excellent (all metrics within thresholds)
    // 2. If any error insights ‚Üí poor (critical issues present)
    // 3. If only warning insights ‚Üí good (optimization recommended)
    const overallHealth = insights.length === 0
      ? "excellent"
      : insights.some((i) => i.type === "error")
      ? "poor"
      : "good";

    return {
      insights,
      overallHealth,
    };
  }
}

// ================================================================================
// üîÑ PERFORMANCE MIDDLEWARE FACTORY
// ================================================================================

/**
 * Generate a unique request ID for tracking
 *
 * ALGORITHM:
 * - Random alphanumeric string (6 chars)
 * - Timestamp in base-36 (shorter than base-10)
 * - Concatenated for uniqueness
 *
 * FORMAT: {random}{timestamp}
 * Example: "a3f2k91n7s9p"
 *
 * WHY NOT SEQUENTIAL?
 * - Sequential IDs reveal traffic volume (security concern)
 * - Random IDs prevent enumeration attacks
 * - Still unique due to timestamp component
 *
 * COLLISION PROBABILITY:
 * - Random component: 36^6 = 2.2 billion possibilities
 * - Timestamp ensures uniqueness within same millisecond
 * - Effectively zero collision probability in practice
 *
 * @private
 * @returns {string} Unique request identifier
 *
 * @example
 * ```typescript
 * generateRequestId()  // "a3f2k91n7s9p"
 * generateRequestId()  // "x9m3l71n7s9q"
 * ```
 */
function generateRequestId(): string {
  // Generate random alphanumeric string
  // Math.random() ‚Üí 0.7234... (random decimal 0-1)
  // .toString(36) ‚Üí "0.q3f2k9..." (base-36: 0-9, a-z)
  // .substring(2, 8) ‚Üí "q3f2k9" (6 characters)
  const randomPart = Math.random().toString(36).substring(2, 8);

  // Current timestamp in base-36 (shorter representation)
  // Date.now() ‚Üí 1697900000000 (Unix timestamp in ms)
  // .toString(36) ‚Üí "1n7s9p" (base-36 representation)
  const timestampPart = Date.now().toString(36);

  // Concatenate for uniqueness
  return randomPart + timestampPart;
}

/**
 * Create Oak middleware for performance monitoring
 *
 * MIDDLEWARE PATTERN:
 * Middleware is a function that:
 * 1. Receives a context object (request/response)
 * 2. Optionally calls next() to pass to next middleware
 * 3. Can modify request/response before or after next()
 *
 * EXECUTION FLOW:
 * ```
 * Request ‚Üí Middleware ‚Üí next() ‚Üí Handler
 *                    ‚Üì               ‚Üì
 * Response ‚Üê Middleware ‚Üê ‚Üê ‚Üê ‚Üê ‚Üê ‚Üê ‚Üê
 * ```
 *
 * WHAT THIS MIDDLEWARE DOES:
 * 1. Captures request start time
 * 2. Increments request counter
 * 3. Generates unique request ID
 * 4. Calls next() to execute handler
 * 5. Measures total time elapsed
 * 6. Records metrics in monitor
 * 7. Adds performance headers
 * 8. Logs in development mode
 * 9. Handles errors gracefully
 *
 * INTEGRATION:
 * ```typescript
 * const monitor = new PerformanceMonitor();
 * app.use(createPerformanceMiddleware(monitor, isDevelopment));
 * ```
 *
 * PERFORMANCE OVERHEAD:
 * - Negligible: <1ms per request
 * - All operations are O(1) constant time
 * - No blocking I/O
 *
 * @public
 * @param {PerformanceMonitor} monitor - Monitor instance to record metrics
 * @param {boolean} isDevelopment - Enable verbose console logging
 * @returns {Function} Oak middleware function
 *
 * @example
 * ```typescript
 * import { Application } from "https://deno.land/x/oak@v12.6.1/mod.ts";
 *
 * const monitor = new PerformanceMonitor();
 * const isDev = Deno.env.get("ENV") === "development";
 *
 * const app = new Application();
 * app.use(createPerformanceMiddleware(monitor, isDev));
 * ```
 */
export function createPerformanceMiddleware(
  monitor: PerformanceMonitor,
  logger: ILogger,
  isDevelopment: boolean = false,
): (ctx: any, next: () => Response | Promise<Response>) => Promise<Response> {
  // Return the actual middleware function
  // Compatible with custom Deno HTTP framework
  const middleware = async (ctx: any, next: () => Response | Promise<Response>): Promise<Response> => {
    // =========================================================================
    // PHASE 1: PRE-REQUEST (Before handler executes)
    // =========================================================================

    // Capture start time (high-resolution timestamp)
    const start = Date.now();

    // Increment total request counter
    // Must be called before next() to ensure it's always incremented
    monitor.incrementRequest();

    // Generate unique ID for request tracking
    // Useful for correlating logs and debugging
    const requestId = generateRequestId();

    // Store metadata in context state
    // ctx.state is a Record<string, unknown> for storing request-scoped data
    ctx.state.requestId = requestId;
    ctx.state.startTime = start;

    // =========================================================================
    // PHASE 2: REQUEST PROCESSING
    // =========================================================================

    try {
      // Execute the next middleware or route handler
      // This is where your application logic runs
      // May involve:
      // - Database queries
      // - API calls
      // - File I/O
      // - Business logic
      const response = await next();

      // -----------------------------------------------------------------------
      // PHASE 3: POST-REQUEST SUCCESS (After successful handler execution)
      // -----------------------------------------------------------------------

      // Calculate elapsed time
      const responseTime = Date.now() - start;

      // Extract request details from context
      const method = ctx.request.method;
      const path = ctx.url.pathname;
      const status = response.status;

      // Record comprehensive metrics
      monitor.recordRequest(path, method, responseTime, status);

      // -----------------------------------------------------------------------
      // ADD PERFORMANCE HEADERS
      // -----------------------------------------------------------------------

      // Clone response to add headers
      const headers = new Headers(response.headers);

      // X-Response-Time: Time taken to process request
      // Useful for client-side performance monitoring
      headers.set("X-Response-Time", `${responseTime}ms`);

      // X-Request-ID: Unique identifier for this request
      // Useful for distributed tracing and log correlation
      headers.set("X-Request-ID", requestId);

      // X-Server-Timing: W3C standard for server timing
      // Format: metric;dur=duration
      // Can be parsed by browser DevTools
      headers.set("X-Server-Timing", `total;dur=${responseTime}`);

      // -----------------------------------------------------------------------
      // DEVELOPMENT LOGGING
      // -----------------------------------------------------------------------

      if (isDevelopment) {
        // Log format: METHOD PATH - STATUS (TIME) [ID]
        const logMessage = `üìä ${method} ${path} - ${status} (${responseTime}ms) [${requestId}]`;
        logger.logInfo(logMessage);

        // Warn about slow requests (>1000ms)
        if (responseTime > 1000) {
          logger.logWarning(`Slow request detected: ${responseTime}ms for ${method} ${path}`);
        }
      }

      // Return response with added headers
      return new Response(response.body, {
        status: response.status,
        statusText: response.statusText,
        headers,
      });
    } catch (error) {
      // -----------------------------------------------------------------------
      // PHASE 3: POST-REQUEST ERROR (After handler throws exception)
      // -----------------------------------------------------------------------

      // Increment error counter
      monitor.incrementError();

      // Calculate time until error
      const responseTime = Date.now() - start;

      // Record failed request with 500 status
      // Even though handler didn't set status, we assume 500 for unhandled errors
      monitor.recordRequest(
        ctx.url.pathname,
        ctx.request.method,
        responseTime,
        500, // Internal Server Error
      );

      // Log error in development mode
      if (isDevelopment) {
        const errorMessage = error instanceof Error ? error.message : String(error);
        logger.logError(
          `Request failed [${requestId}] after ${responseTime}ms`,
          { error: errorMessage },
        );

        // Optional: log full stack trace
        if (error instanceof Error && error.stack) {
          logger.logError("Stack trace", { stack: error.stack });
        }
      }

      // Re-throw error for upstream error handling middleware
      // This ensures error handlers further up the stack can process it
      throw error;
    }
  };

  Object.defineProperty(middleware, "name", { value: "performanceMonitor" });
  return middleware;
}

// ================================================================================
// üéØ PERFORMANCE UTILITIES
// ================================================================================

/**
 * Advanced performance analysis tools
 *
 * STATIC CLASS PATTERN:
 * - All methods are static (no instance needed)
 * - Pure functions (no side effects)
 * - Utility class for analysis algorithms
 *
 * USE CASES:
 * - Administrative dashboards
 * - Performance audits
 * - Optimization planning
 * - Capacity planning
 *
 * @example
 * ```typescript
 * const analysis = PerformanceAnalyzer.analyzeEndpointPerformance(monitor);
 * console.log('Slowest endpoints:', analysis.slowestEndpoints);
 * console.log('Recommendations:', analysis.recommendations);
 * ```
 */
export class PerformanceAnalyzer {
  /**
   * Analyze endpoint performance and generate recommendations
   *
   * ANALYSIS CATEGORIES:
   * 1. Slowest Endpoints - Ordered by average response time
   * 2. Error-Prone Endpoints - Ordered by error rate
   * 3. Popular Endpoints - Ordered by request count
   * 4. Recommendations - Actionable optimization suggestions
   *
   * ALGORITHMS:
   * - All use sorting: O(n log n) time complexity
   * - Take top 5 from each category
   * - Cross-reference for recommendation generation
   *
   * @public
   * @static
   * @param {PerformanceMonitor} monitor - Monitor instance to analyze
   * @returns {Object} Comprehensive endpoint analysis
   *
   * @example
   * ```typescript
   * const analysis = PerformanceAnalyzer.analyzeEndpointPerformance(monitor);
   *
   * analysis.slowestEndpoints.forEach(ep => {
   *   console.log(`${ep.endpoint}: ${ep.avgResponseTime}ms avg`);
   * });
   *
   * analysis.recommendations.forEach(rec => {
   *   console.log(`[${rec.type}] ${rec.message}`);
   * });
   * ```
   */
  static analyzeEndpointPerformance(monitor: PerformanceMonitor): {
    slowestEndpoints: Array<{
      endpoint: string;
      requests: number;
      avgResponseTime: string;
      errorRate: string;
    }>;
    errorProneEndpoints: Array<{
      endpoint: string;
      requests: number;
      avgResponseTime: string;
      errorRate: string;
    }>;
    popularEndpoints: Array<{
      endpoint: string;
      requests: number;
      avgResponseTime: string;
      errorRate: string;
    }>;
    recommendations: Array<{
      type: string;
      message: string;
      endpoints?: string[];
    }>;
  } {
    // Get detailed metrics with full endpoint breakdown
    const metrics = monitor.getDetailedMetrics();

    return {
      // Endpoints sorted by slowest average response time
      // Identifies performance bottlenecks
      slowestEndpoints: metrics.endpoints
        .sort((a, b) => parseInt(b.avgResponseTime) - parseInt(a.avgResponseTime))
        .slice(0, 5),

      // Endpoints sorted by highest error rate
      // Identifies reliability issues
      errorProneEndpoints: metrics.endpoints
        .filter((e) => parseFloat(e.errorRate) > 0) // Only endpoints with errors
        .sort((a, b) => parseFloat(b.errorRate) - parseFloat(a.errorRate))
        .slice(0, 5),

      // Endpoints sorted by most requests
      // Identifies high-traffic areas
      popularEndpoints: metrics.endpoints
        .sort((a, b) => b.requests - a.requests)
        .slice(0, 5),

      // AI-generated recommendations based on analysis
      recommendations: this.generateRecommendations(metrics),
    };
  }

  /**
   * Generate actionable performance recommendations
   *
   * RECOMMENDATION TYPES:
   * 1. Caching - For high-traffic GET endpoints
   * 2. Error Handling - For endpoints with high error rates
   * 3. Optimization - For slow endpoints
   * 4. Scaling - For capacity planning
   *
   * ALGORITHM:
   * - Analyzes endpoint patterns
   * - Identifies optimization opportunities
   * - Generates specific, actionable advice
   *
   * @private
   * @static
   * @param {any} metrics - Detailed metrics object
   * @returns {Array<Object>} List of recommendations
   *
   * @example
   * ```typescript
   * const recs = PerformanceAnalyzer.generateRecommendations(metrics);
   * // [
   * //   {
   * //     type: 'caching',
   * //     message: 'Consider implementing caching for high-traffic GET endpoints',
   * //     endpoints: ['GET /api/users', 'GET /api/products']
   * //   },
   * //   ...
   * // ]
   * ```
   */
  private static generateRecommendations(metrics: any) {
    const recommendations = [];

    // =========================================================================
    // RECOMMENDATION 1: CACHING OPPORTUNITIES
    // =========================================================================

    // Find GET endpoints with high traffic (>100 requests)
    // GET requests are idempotent and safe to cache
    const highTrafficEndpoints = metrics.endpoints
      .filter((e: any) => e.requests > 100 && e.endpoint.startsWith("GET"))
      .sort((a: any, b: any) => b.requests - a.requests);

    if (highTrafficEndpoints.length > 0) {
      recommendations.push({
        type: "caching",
        message: "Consider implementing caching for high-traffic GET endpoints",
        endpoints: highTrafficEndpoints.slice(0, 3).map((e: any) => e.endpoint),
      });
    }

    // =========================================================================
    // RECOMMENDATION 2: ERROR HANDLING REVIEW
    // =========================================================================

    // Find endpoints with error rate >5%
    // Indicates systematic issues requiring investigation
    const errorProneEndpoints = metrics.endpoints
      .filter((e: any) => parseFloat(e.errorRate) > 5);

    if (errorProneEndpoints.length > 0) {
      recommendations.push({
        type: "error-handling",
        message: "Review error handling for endpoints with high error rates",
        endpoints: errorProneEndpoints.map((e: any) => e.endpoint),
      });
    }

    // =========================================================================
    // RECOMMENDATION 3: PERFORMANCE OPTIMIZATION
    // =========================================================================

    // Find endpoints with average response time >500ms
    // Indicates need for optimization
    const slowEndpoints = metrics.endpoints
      .filter((e: any) => parseInt(e.avgResponseTime) > 500);

    if (slowEndpoints.length > 0) {
      recommendations.push({
        type: "optimization",
        message: "Optimize slow endpoints to improve overall performance",
        endpoints: slowEndpoints.slice(0, 3).map((e: any) => e.endpoint),
      });
    }

    return recommendations;
  }
}

// ================================================================================
// üöÄ DEFAULT EXPORT
// ================================================================================

/**
 * Default export for convenient importing
 *
 * USAGE:
 * ```typescript
 * import perfMonitor from "./middleware/performanceMonitor.ts";
 *
 * const monitor = new perfMonitor.PerformanceMonitor();
 * app.use(perfMonitor.createPerformanceMiddleware(monitor));
 * ```
 */
export default {
  PerformanceMonitor,
  createPerformanceMiddleware,
  PerformanceAnalyzer,
};

// ================================================================================
// END OF FILE
// ================================================================================
